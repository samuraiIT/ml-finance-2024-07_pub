{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ccxt\n",
    "import time\n",
    "import pandas as pd\n",
    "import pyarrow.parquet as pq\n",
    "import pyarrow as pa\n",
    "import plotly.express as px\n",
    "from datetime import datetime\n",
    "\n",
    "    # Все возможно-доступные биржи: ['ace', 'alpaca', 'ascendex', 'bequant', 'bigone', 'binance', 'binancecoinm', 'binanceus', 'binanceusdm', 'bingx', 'bit2c', 'bitbank', 'bitbns', \n",
    "    # 'bitcoincom', 'bitfinex', 'bitfinex2', 'bitflyer', 'bitget', 'bithumb', 'bitmart', 'bitmex', 'bitopro', 'bitpanda', 'bitrue', 'bitso', 'bitstamp', 'bitteam', \n",
    "    # 'bitvavo', 'bl3p', 'blockchaincom', 'blofin', 'btcalpha', 'btcbox', 'btcmarkets', 'btcturk', 'bybit', 'cex', 'coinbase', 'coinbaseadvanced', 'coinbaseexchange', \n",
    "    # 'coinbaseinternational', 'coincheck', 'coinex', 'coinlist', 'coinmate', 'coinmetro', 'coinone', 'coinsph', 'coinspot', 'cryptocom', 'currencycom', 'delta', 'deribit', 'digifinex', \n",
    "    # 'exmo', 'fmfwio', 'gate', 'gateio', 'gemini', 'hashkey', 'hitbtc', 'hollaex', 'htx', 'huobi', 'huobijp', 'hyperliquid', 'idex', 'independentreserve', 'indodax', 'kraken', 'krakenfutures', \n",
    "    # 'kucoin', 'kucoinfutures', 'kuna', 'latoken', 'lbank', 'luno', 'lykke', 'mercado', 'mexc', 'ndax', 'novadax', 'oceanex', 'okcoin', 'okx', 'onetrading', 'oxfun', 'p2b', 'paradex', 'paymium', \n",
    "    # 'phemex', 'poloniex', 'poloniexfutures', 'probit', 'timex', 'tokocrypto', 'tradeogre', 'upbit', 'vertex', 'wavesexchange', 'wazirx', 'whitebit', 'woo', 'woofipro', 'xt', 'yobit', 'zaif', 'zonda']\n",
    "# Создаем объект биржи\n",
    "exchange = ccxt.binance()\n",
    "\n",
    "    # TOP Список торговых пар\n",
    "    # trading_pairs = [\"BTC/USDT\", \"ETH/USDT\", \"BNB/USDT\", \"SOL/USDT\", \"XRP/USDT\", \"DOGE/USDT\", \"ADA/USDT\", \"TRX/USDT\",\n",
    "    #    \"AVAX/USDT\", \"SHIB/USDT\", \"DOT/USDT\", \"LINK/USDT\", \"BCH/USDT\", \"NEAR/USDT\", \"MATIC/USDT\", \"LTC/USDT\",\n",
    "    #    \"UNI/USDT\", \"PEPE/USDT\", \"/BTC/ETH/BTC\", \"BNB/BTC\", \"SOL/BTC\", \"XRP/BTC\", \"DOGE/BTC\", \"ADA/BTC\", \"TRX/BTC\",\n",
    "    #    \"AVAX/BTC\", \"DOT/BTC\", \"LINK/BTC\", \"BCH/BTC\", \"NEAR/BTC\", \"MATIC/BTC\", \"LTC/BTC\", \"UNI/BTC\", \"SOL/BNB\",\n",
    "    #    \"XRP/BNB\", \"ADA/BNB\", \"TRX/BNB\", \"AVAX/BNB\", \"DOT/BNB\", \"LINK/BNB\", \"BCH/BNB\", \"NEAR/BNB\", \"MATIC/BNB\",\n",
    "    #    \"LTC/BNB\", \"XRP/ETH\", \"SOL/ETH\", \"ADA/ETH\", \"TRX/ETH\", \"AVAX/ETH\"]\n",
    "# Список торговых пар, по которым будем загружать данные\n",
    "trading_pairs = [\n",
    "    \"BTC/USDT\", \"ETH/USDT\", \"BNB/USDT\", \"SOL/USDT\"\n",
    "]\n",
    "\n",
    "# Таймфрейм для загрузки данных ('5m' означает 5 минут)\n",
    "timeframe = '5m'\n",
    "\n",
    "# Начальная дата для загрузки данных (в формате ISO 8601)\n",
    "since = exchange.parse8601('2024-01-01T00:00:00Z')\n",
    "# Текущее время в миллисекундах\n",
    "now = exchange.milliseconds()\n",
    "\n",
    "# Функция для загрузки исторических данных (OHLCV) для заданной пары и таймфрейма\n",
    "def fetch_data(pair, timeframe, since, now):\n",
    "    all_ohlcv = []  # Список для хранения всех данных\n",
    "    while since < now:\n",
    "        try:\n",
    "            # Загружаем данные OHLCV (Open, High, Low, Close, Volume) с биржи\n",
    "            ohlcv = exchange.fetch_ohlcv(pair, timeframe, since, limit=1000)\n",
    "            if not ohlcv:  # Если данных нет, прерываем цикл\n",
    "                break\n",
    "            all_ohlcv.extend(ohlcv)  # Добавляем данные в список\n",
    "            since = ohlcv[-1][0] + 1  # Обновляем начальное время для следующего запроса\n",
    "            time.sleep(exchange.rateLimit / 1000)  # Пауза для соблюдения лимитов API биржи\n",
    "        except Exception as e:\n",
    "            # Обработка ошибок, если что-то пошло не так\n",
    "            print(f\"Ошибка при загрузке данных для {pair}: {e}\")\n",
    "            break\n",
    "    return all_ohlcv\n",
    "\n",
    "# Функция для проверки данных перед сохранением\n",
    "def check_data_integrity(df):\n",
    "    \"\"\"\n",
    "    Проверяет целостность данных: пропуски и аномалии.\n",
    "    \"\"\"\n",
    "    print(\"Проверка данных на пропуски и аномалии...\")\n",
    "    # Проверяем наличие пропусков в данных\n",
    "    if df.isnull().values.any():\n",
    "        print(\"Обнаружены пропуски в данных! Сохранение невозможно.\")\n",
    "        return False\n",
    "\n",
    "    # Проверка на наличие выбросов по стандартным значениям\n",
    "    z_scores = (df[['open', 'high', 'low', 'close']] - df[['open', 'high', 'low', 'close']].mean()) / df[['open', 'high', 'low', 'close']].std()\n",
    "    if (z_scores.abs() > 3).any().any():\n",
    "        print(\"Обнаружены аномалии в данных! Сохранение невозможно.\")\n",
    "        return False\n",
    "\n",
    "    print(\"Данные проверены и корректны.\")\n",
    "    return True\n",
    "\n",
    "# Функция для сохранения данных в формате Parquet (с пятиминутными интервалами)\n",
    "def save_to_parquet(data, pair):\n",
    "    # Преобразуем данные в DataFrame для удобного анализа и хранения\n",
    "    df = pd.DataFrame(data, columns=['timestamp', 'open', 'high', 'low', 'close', 'volume'])\n",
    "    df['timestamp'] = pd.to_datetime(df['timestamp'], unit='ms')  # Конвертируем timestamp в читаемый формат\n",
    "    \n",
    "    # Проверяем данные перед сохранением\n",
    "    if not check_data_integrity(df):\n",
    "        print(f\"Данные для {pair} не сохранены из-за ошибок.\")\n",
    "        return None\n",
    "    \n",
    "    # Преобразуем DataFrame в формат Parquet и сохраняем на диск (пятиминутные интервалы)\n",
    "    df.reset_index(drop=True, inplace=True)  # Сбрасываем индекс перед сохранением\n",
    "    table = pa.Table.from_pandas(df)\n",
    "    pq.write_table(table, f\"{pair.replace('/', '_')}_5m.parquet\")\n",
    "    print(f\"Пятиминутные данные для {pair} успешно сохранены.\")\n",
    "    return df\n",
    "\n",
    "# Функция для ресемплинга данных в другой таймфрейм (например, 1ч, 4ч, 1д)\n",
    "def resample_dataset(df: pd.DataFrame, time: str):\n",
    "    \"\"\"\n",
    "    Ресемплинг данных для конвертации таймфрейма (например, 1ч, 4ч, 1д).\n",
    "    \"\"\"\n",
    "    df = df.set_index('timestamp')  # Устанавливаем timestamp в качестве индекса\n",
    "    curent_df_high = df['high'].resample(time).max()  # Высокая цена за период\n",
    "    curent_df_low = df['low'].resample(time).min()    # Низкая цена за период\n",
    "    curent_df_close = df['close'].resample(time).last()  # Последняя цена за период\n",
    "    curent_df_open = df['open'].resample(time).first()  # Первая цена за период\n",
    "    curent_df_volume = df['volume'].resample(time).sum()  # Общий объем за период\n",
    "    \n",
    "    # Собираем итоговый DataFrame\n",
    "    final_df = pd.DataFrame({\n",
    "        'open': curent_df_open,\n",
    "        'close': curent_df_close,\n",
    "        'high': curent_df_high,\n",
    "        'low': curent_df_low,\n",
    "        'volume': curent_df_volume\n",
    "    })\n",
    "    \n",
    "    # Удаляем строки с отсутствующими данными\n",
    "    final_df = final_df.dropna()\n",
    "    \n",
    "    # Восстанавливаем временные метки для дальнейшей обработки\n",
    "    final_df.reset_index(inplace=True)\n",
    "    return final_df\n",
    "\n",
    "# Функция для загрузки данных из .parquet файла\n",
    "def load_data_from_parquet(file_path):\n",
    "    \"\"\"\n",
    "    Загрузка данных из .parquet файла.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        df = pd.read_parquet(file_path)\n",
    "        print(f\"Данные загружены из {file_path}\")\n",
    "        return df\n",
    "    except Exception as e:\n",
    "        print(f\"Ошибка при загрузке данных из {file_path}: {e}\")\n",
    "        return None\n",
    "\n",
    "# Функция для построения графика цен закрытия\n",
    "def plot_parquet_data(df, pair):\n",
    "    \"\"\"\n",
    "    Построение графика цен закрытия для определенной пары на основе данных из parquet.\n",
    "    \"\"\"\n",
    "    if df is not None and 'timestamp' in df and 'close' in df:\n",
    "        fig = px.line(df, x='timestamp', y='close', title=f'Close Price of {pair}')\n",
    "        fig.show(renderer=\"browser\")  # Открытие графика в браузере\n",
    "    else:\n",
    "        print(\"Данные некорректны или отсутствуют столбцы 'timestamp' и 'close'\")\n",
    "\n",
    "# Основной цикл по всем торговым парам из списка\n",
    "for pair in trading_pairs:\n",
    "    print(f\"Загружаем данные для {pair}...\")\n",
    "    data = fetch_data(pair, timeframe, since, now)  # Загружаем данные для каждой пары\n",
    "    \n",
    "    if data:  # Если данные успешно загружены\n",
    "        print(f\"Сохраняем пятиминутные данные для {pair}...\")\n",
    "        df = save_to_parquet(data, pair)  # Сохраняем пятиминутные данные в Parquet\n",
    "        \n",
    "        if df is not None:\n",
    "            print(f\"Данные для {pair} успешно сохранены в пятиминутках.\")\n",
    "    else:\n",
    "        print(f\"Данные для {pair} не найдены или загрузка завершилась неудачей.\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Конвертация данных в другие таймфреймы\n",
    "for pair in trading_pairs:\n",
    "    try:\n",
    "        df_5m = pd.read_parquet(f\"{pair.replace('/', '_')}_5m.parquet\")\n",
    "        \n",
    "        print(f\"Преобразуем данные для {pair} в другие таймфреймы...\")\n",
    "        \n",
    "        # Пример конвертации в 1 час\n",
    "        resampled_df_1h = resample_dataset(df_5m, '1H')\n",
    "        pq.write_table(pa.Table.from_pandas(resampled_df_1h), f\"{pair.replace('/', '_')}_1h.parquet\")\n",
    "        \n",
    "        # Пример конвертации в 4 часа\n",
    "        resampled_df_4h = resample_dataset(df_5m, '4H')\n",
    "        pq.write_table(pa.Table.from_pandas(resampled_df_4h), f\"{pair.replace('/', '_')}_4h.parquet\")\n",
    "        \n",
    "        # Пример конвертации в 1 день\n",
    "        resampled_df_1d = resample_dataset(df_5m, '1D')\n",
    "        pq.write_table(pa.Table.from_pandas(resampled_df_1d), f\"{pair.replace('/', '_')}_1d.parquet\")\n",
    "    except Exception as e:\n",
    "        print(f\"Ошибка при конвертации данных для {pair}: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Построение графиков для каждого таймфрейма\n",
    "for pair in trading_pairs:\n",
    "    for timeframe in ['5m', '1h', '4h', '1d']:\n",
    "        file_path = f\"{pair.replace('/', '_')}_{timeframe}.parquet\"\n",
    "        df = load_data_from_parquet(file_path)\n",
    "        plot_parquet_data(df, pair)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
